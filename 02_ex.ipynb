{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1400d04be3274704",
   "metadata": {},
   "source": [
    "# Exercise 2\n",
    "## Authors: E. Vercesi; A. Dei Rossi, S. Huber*, L. Scarciglia.\n",
    "\n",
    "In this exercise session you are going to learn the basics of PyTorch and pandas. We will start with PyTorch.\n",
    "\n",
    "[PyTorch](https://pytorch.org/) is a Python library for scientific computing (as much as NumPy), but which can additionally run on GPUs. \n",
    "Hence, this is the computing library of choice for Deep Learning applications. \n",
    "PyTorch is developed by Meta. You might have also heard of its main competitor TensorFlow (Google). Although both have basically the same functionalities, in this course we would like you to stick to PyTorch (assignments made using TensorFlow won't be evaluated).\n",
    "\n",
    "If you haven't done Exercise 1 on NumPy yet, we highly encourage to do it first: NumPy and PyTorch offer a vast overlap of functionalities, so understanding NumPy first is going to boost greatly your understanding of PyTorch.\n",
    "To begin with, make sure you have installed it. If not, please do so (by typing `conda/pip install torch` from your environment, or using the GUI of your IDE). Also make sure that the version installed is 2.8.\n",
    "\n",
    "In addition to that, also install [pandas](https://pandas.pydata.org/docs/getting_started/install.html). We will use it at the end of the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "85fa3c9d5375899a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-18T19:31:50.547971Z",
     "start_time": "2024-09-18T19:31:50.545559Z"
    },
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x204fc09e310>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch  # If you see errors, use conda or pip to install torch in your virtual environment.\n",
    "import numpy as np\n",
    "\n",
    "torch.manual_seed(42)  # manual seed is to ensure repeatability of random numbers. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "166656a7be8fb629",
   "metadata": {},
   "source": [
    "## Create tensors\n",
    "\n",
    "Tensors are like NumPy arrays, but they can live in GPUs.\n",
    "\n",
    "1. Create a tensor out of a Python list [1, 2, 3].\n",
    "2. Create a tensor out of a NumPy array [[2, 3, 4], [4, 3, 2]] (see method [`.from_numpy()`](https://pytorch.org/docs/stable/generated/torch.from_numpy.html)).\n",
    "3. Convert the tensor of point 2 back to a NumPy array. (see method [`.numpy()`](https://pytorch.org/docs/stable/generated/torch.Tensor.numpy.html))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6628425e43a4729a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-18T19:44:01.942448Z",
     "start_time": "2024-09-18T19:44:01.939947Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3])\n",
      "tensor([[2, 3, 4],\n",
      "        [4, 3, 2]])\n",
      "[[2 3 4]\n",
      " [4 3 2]]\n"
     ]
    }
   ],
   "source": [
    "## 1: create a tensor out of a Python list\n",
    "py_t = torch.tensor([1,2,3])\n",
    "print(py_t)\n",
    "## 2: create a tensor out of a NumPy array\n",
    "np_t = torch.from_numpy(np.array([[2,3,4],[4,3,2]]))\n",
    "print(np_t)\n",
    "## 3: Convert the tensor back to NumPy.\n",
    "np_l = np_t.numpy()\n",
    "print(np_l)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6e04eaff1b59988",
   "metadata": {},
   "source": [
    "1. Check the `.dtype` attribute of the above created tensors. \n",
    "2. Create a tensor of size 3 with values [1, 2, 3] but forcing the dtype to be float64."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "701958d3e03ea301",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-18T19:45:12.850223Z",
     "start_time": "2024-09-18T19:45:12.847542Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "py_t: torch.int64 np_t: torch.int64 np_l: int64\n",
      "tensor([1., 2., 3.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "## 1: check the dtype attribute\n",
    "print(\"py_t:\", py_t.dtype, \"np_t:\", np_t.dtype, \"np_l:\", np_l.dtype)\n",
    "## 2: create [1, 2, 3] with dtype float64\n",
    "t_float = torch.tensor([1,2,3], dtype=torch.float64)\n",
    "print(t_float)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a49bf6b0cbecf456",
   "metadata": {},
   "source": [
    "PyTorch also offers some more advanced functions that can be used to create well-known matrices:\n",
    "\n",
    "1. Create an identity matrix of size (5, 5) (see [`torch.eye()`](https://pytorch.org/docs/stable/generated/torch.eye.html)).\n",
    "2. Create a matrix of all zeros of size (3, 4) (see [`torch.zeros()`](https://pytorch.org/docs/stable/generated/torch.zeros.html).\n",
    "3. Create a matrix of all ones of size (2, 3) (see [`torch.ones()`](https://pytorch.org/docs/stable/generated/torch.ones.html).\n",
    "4. Given a tensor of size (3, 2) of your choice, create a matrix of the same size (3, 2) filled with ones (equivalently zeros) (see [`torch.zeros_like()`](https://pytorch.org/docs/stable/generated/torch.zeros_like.html).\n",
    "5. Create a matrix of size (3, 4) filled with numbers from 0 to 11 inclusive (same as in NumPy). Try both [`torch.arange()`](https://pytorch.org/docs/stable/generated/torch.arange.html) and [`torch.linspace()`](https://pytorch.org/docs/stable/generated/torch.linspace.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "58eba4bbd65d8a27",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-18T19:56:37.567665Z",
     "start_time": "2024-09-18T19:56:37.564862Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 5])\n",
      "torch.Size([3, 4])\n",
      "torch.Size([2, 3])\n",
      "tensor([[2, 7],\n",
      "        [6, 4],\n",
      "        [6, 5]])\n",
      "tensor([[0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0]])\n",
      "tensor([[1, 1],\n",
      "        [1, 1],\n",
      "        [1, 1]])\n",
      "tensor([[ 0,  1,  2,  3],\n",
      "        [ 4,  5,  6,  7],\n",
      "        [ 8,  9, 10, 11]])\n",
      "tensor([[ 0.,  1.,  2.,  3.],\n",
      "        [ 4.,  5.,  6.,  7.],\n",
      "        [ 8.,  9., 10., 11.]])\n"
     ]
    }
   ],
   "source": [
    "## 1: torch.eye()\n",
    "id_m = torch.eye(5)\n",
    "print(id_m.shape)\n",
    "## 2: torch.zeros()\n",
    "m_zeros = torch.zeros((3,4))\n",
    "print(m_zeros.shape)\n",
    "## 3: torch.ones()\n",
    "m_ones = torch.ones((2,3))\n",
    "print(m_ones.shape)\n",
    "## 4: torch.zeros_like()\n",
    "m_rand = torch.randint(0,10,(3,2))\n",
    "print(m_rand)\n",
    "print(torch.zeros_like(m_rand))\n",
    "print(torch.ones_like(m_rand))\n",
    "## 5:\n",
    "## torch.arange()\n",
    "print(torch.arange(0, 12).reshape((3,4)))\n",
    "## torch.linspace()\n",
    "print(torch.linspace(0,11,12).reshape(3,4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e58877dfd4627fc",
   "metadata": {},
   "source": [
    "### Random tensors\n",
    "\n",
    "As in NumPy, you have a big choice of random distributions to sample you arrays from.\n",
    "Create the same random arrays you did in NumPy in Exercise 1:\n",
    "1) Create a random tensor of size 4 of uniform floating point numbers in the interval [0, 1). (see [`torch.rand`](https://pytorch.org/docs/stable/generated/torch.rand.html)).\n",
    "2) Create a random tensor of size (3, 2) of uniform floating point numbers in the interval [0, 5). (hint: generate numbers in the interval [0, 1) and scale them up by 5).\n",
    "3) Create a random tensor of size (2, 1, 2) of integers in the interval [10, 20]. (see [`torch.randint`](https://pytorch.org/docs/stable/generated/torch.randint.html), caraful with border conditions).\n",
    "4) Create a random tensor of size 10 over the normal distribution, mean 3 and std dev 2. (see [`torch.normal`](https://pytorch.org/docs/stable/generated/torch.normal.html))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "108b3718b4ff25d3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-18T20:29:56.713417Z",
     "start_time": "2024-09-18T20:29:56.707816Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.2566, 0.7936, 0.9408, 0.1332])\n",
      "tensor([4.6730, 2.9679, 4.3470, 2.8386, 3.7055])\n",
      "tensor([[[10, 14]],\n",
      "\n",
      "        [[13, 16]]])\n",
      "tensor([[5.4422, 3.3022, 2.3362, 2.0430, 2.4739, 2.6429, 0.6283, 1.2279, 1.5701,\n",
      "         3.2560]])\n"
     ]
    }
   ],
   "source": [
    "## 1: torch.rand()\n",
    "print(torch.rand(4))\n",
    "## 2: torch.rand() scaled up to [0, 5)\n",
    "print(torch.rand(5)*5)\n",
    "## 3: torch.randint()\n",
    "print(torch.randint(10,21,(2,1,2)))\n",
    "## 4: torch.normal()\n",
    "print(torch.normal(3, 2, size=(1,10)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68d972460fb05e0a",
   "metadata": {},
   "source": [
    "## Working with tensors' dimensions\n",
    "\n",
    "In this section we will learn how to manipulate tensor's dimensions. Notice that they are extremely similar to NumPy methods: hence, if you have done exercise 1, this section should be quite straightforward.\n",
    "\n",
    "### Access elements and slicing \n",
    "\n",
    "Create an identity matrix of size (4, 4) and access \n",
    "1. The element in position [0, 0].\n",
    "2. The last element.\n",
    "3. Element in position [2, 3].\n",
    "Check that the returned elements are what you expect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "60958f0e86811752",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-19T06:54:09.454500Z",
     "start_time": "2024-09-19T06:54:09.451717Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 0., 0.],\n",
      "        [0., 1., 0., 0.],\n",
      "        [0., 0., 1., 0.],\n",
      "        [0., 0., 0., 1.]])\n",
      "tensor(1.)\n",
      "tensor(1.)\n",
      "tensor(0.)\n"
     ]
    }
   ],
   "source": [
    "# Create the identity matrix\n",
    "id_m = torch.eye(4)\n",
    "print(id_m)\n",
    "## 1: access element in [0, 0]\n",
    "print(id_m[0,0])\n",
    "## 2: access element in [3, 3]\n",
    "print(id_m[3,3])\n",
    "## 3: access element in [2, 3]\n",
    "print(id_m[3,2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48e067adf3b30b97",
   "metadata": {},
   "source": [
    "### Slicing\n",
    "\n",
    "1. Create a random tensor of size (3, 4) of integers in the interval [5, 10].\n",
    "2. Print the second row.\n",
    "3. Print the third column.\n",
    "4. Print the sub-matrix spanning from the second to the third row, from the second to the third column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dddd2e53d3e6ac70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 5,  7,  5,  6],\n",
      "        [ 8,  8, 10, 10],\n",
      "        [ 9,  8, 10,  5]])\n",
      "tensor([ 8,  8, 10, 10])\n",
      "tensor([ 5, 10, 10])\n",
      "tensor([[ 8, 10],\n",
      "        [ 8, 10]])\n"
     ]
    }
   ],
   "source": [
    "## 1: create a random tensor of size [3, 4].\n",
    "rand_m = torch.randint(5,11,(3,4))\n",
    "print(rand_m)\n",
    "## 2: print the second row.\n",
    "print(rand_m[1])\n",
    "## 3: print the third column.\n",
    "print(rand_m[:,2])\n",
    "## 4: sub-matrix\n",
    "print(rand_m[1:,1:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c97683b8-c4b4-4060-94b4-a549a61eccff",
   "metadata": {},
   "source": [
    "### Access tensors' dimensions\n",
    "\n",
    "1. Create a tensor $v$ of size (3, 4, 2, 4, 1) of random floats in [0, 1).\n",
    "2. Print its shape. You can use both `.shape` and [`.size()`](https://docs.pytorch.org/docs/stable/generated/torch.Tensor.size.html), try them both.\n",
    "3. Print its third dimension's size (2 in our example). Check [`.size()`](https://docs.pytorch.org/docs/stable/generated/torch.Tensor.size.html) function.\n",
    "4. Print the number of dimensions of our vector (5 in our example). Check [`.dim()`](https://docs.pytorch.org/docs/stable/generated/torch.Tensor.dim.html#torch.Tensor.dim) or [`.ndim`](https://docs.pytorch.org/docs/stable/generated/torch.Tensor.dim.html#torch.Tensor.ndim)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "602276de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[[0.3068],\n",
      "           [0.1165],\n",
      "           [0.9103],\n",
      "           [0.6440]],\n",
      "\n",
      "          [[0.7071],\n",
      "           [0.6581],\n",
      "           [0.4913],\n",
      "           [0.8913]]],\n",
      "\n",
      "\n",
      "         [[[0.1447],\n",
      "           [0.5315],\n",
      "           [0.1587],\n",
      "           [0.6542]],\n",
      "\n",
      "          [[0.3278],\n",
      "           [0.6532],\n",
      "           [0.3958],\n",
      "           [0.9147]]],\n",
      "\n",
      "\n",
      "         [[[0.2036],\n",
      "           [0.2018],\n",
      "           [0.2018],\n",
      "           [0.9497]],\n",
      "\n",
      "          [[0.6666],\n",
      "           [0.9811],\n",
      "           [0.0874],\n",
      "           [0.0041]]],\n",
      "\n",
      "\n",
      "         [[[0.1088],\n",
      "           [0.1637],\n",
      "           [0.7025],\n",
      "           [0.6790]],\n",
      "\n",
      "          [[0.9155],\n",
      "           [0.2418],\n",
      "           [0.1591],\n",
      "           [0.7653]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[0.2979],\n",
      "           [0.8035],\n",
      "           [0.3813],\n",
      "           [0.7860]],\n",
      "\n",
      "          [[0.1115],\n",
      "           [0.2477],\n",
      "           [0.6524],\n",
      "           [0.6057]]],\n",
      "\n",
      "\n",
      "         [[[0.3725],\n",
      "           [0.7980],\n",
      "           [0.8399],\n",
      "           [0.1374]],\n",
      "\n",
      "          [[0.2331],\n",
      "           [0.9578],\n",
      "           [0.3313],\n",
      "           [0.3227]]],\n",
      "\n",
      "\n",
      "         [[[0.0162],\n",
      "           [0.2137],\n",
      "           [0.6249],\n",
      "           [0.4340]],\n",
      "\n",
      "          [[0.1371],\n",
      "           [0.5117],\n",
      "           [0.1585],\n",
      "           [0.0758]]],\n",
      "\n",
      "\n",
      "         [[[0.2247],\n",
      "           [0.0624],\n",
      "           [0.1816],\n",
      "           [0.9998]],\n",
      "\n",
      "          [[0.5944],\n",
      "           [0.6541],\n",
      "           [0.0337],\n",
      "           [0.1716]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[0.3336],\n",
      "           [0.5782],\n",
      "           [0.0600],\n",
      "           [0.2846]],\n",
      "\n",
      "          [[0.2007],\n",
      "           [0.5014],\n",
      "           [0.3139],\n",
      "           [0.4654]]],\n",
      "\n",
      "\n",
      "         [[[0.1612],\n",
      "           [0.1568],\n",
      "           [0.2083],\n",
      "           [0.3289]],\n",
      "\n",
      "          [[0.1054],\n",
      "           [0.9192],\n",
      "           [0.4008],\n",
      "           [0.9302]]],\n",
      "\n",
      "\n",
      "         [[[0.6558],\n",
      "           [0.0766],\n",
      "           [0.8460],\n",
      "           [0.3624]],\n",
      "\n",
      "          [[0.3083],\n",
      "           [0.0850],\n",
      "           [0.0029],\n",
      "           [0.6431]]],\n",
      "\n",
      "\n",
      "         [[[0.3908],\n",
      "           [0.6947],\n",
      "           [0.0897],\n",
      "           [0.8712]],\n",
      "\n",
      "          [[0.1330],\n",
      "           [0.4137],\n",
      "           [0.6044],\n",
      "           [0.7581]]]]])\n",
      "v shape: torch.Size([3, 4, 2, 4, 1]) v size(): torch.Size([3, 4, 2, 4, 1])\n",
      "2\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "## 1: create a random tensor v of size (3, 4, 2, 4, 1).\n",
    "v = torch.rand(3,4,2,4,1)\n",
    "print(v)\n",
    "## 2: print v's shape using .shape and .size().\n",
    "print(\"v shape:\", v.shape, \"v size():\", v.size())\n",
    "## 3: print the size of the third dimension of v.\n",
    "print(v.size(2))\n",
    "## 4: print the number of dimensions of v.\n",
    "print(v.ndim)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3beec5d76fa615b",
   "metadata": {},
   "source": [
    "## Permute dimensions\n",
    "\n",
    "You can invert the order of the dimensions of a tensor. Create a random tensor of integers in the interval [0, 10) of size (2, 3, 4) and permute its dimensions so that the final size is (4, 2, 3). See [`torch.permute`](https://pytorch.org/docs/stable/generated/torch.permute.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c1e286754f2b797f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-19T07:01:03.982170Z",
     "start_time": "2024-09-19T07:01:03.979816Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 4])\n",
      "torch.Size([4, 2, 3])\n"
     ]
    }
   ],
   "source": [
    "## 1: Create a random tensor. Check its shape (2, 3, 4)\n",
    "rand_int = torch.randint(0,10,(2,3,4))\n",
    "print(rand_int.shape)\n",
    "## 2: Permute its dimensions. Check its shape (4, 2, 3)\n",
    "perm_t = torch.permute(rand_int, (2,0,1))\n",
    "print(perm_t.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d684fd09d5a4bb8",
   "metadata": {},
   "source": [
    "## Squeeze/unsqueeze\n",
    "\n",
    "If you want increase the number of dimensions of your vector (similar to `np.newaxis`, this might turn useful in the context of broadcasting), you can use [`torch.unsqueeze`](https://pytorch.org/docs/stable/generated/torch.unsqueeze.html). If you want to reduce the number of dimensions of your vector by dropping dimensions of size 1 you can use [`torch.squeeze`](https://pytorch.org/docs/stable/generated/torch.squeeze.html) instead.\n",
    "\n",
    "1. Create a random tensor uniform in [0, 1) of size (2, 2). Insert a new dimension so that the final shape is (2, 1, 2).\n",
    "2. Add a dimension to the tensor of point 1, so that the final shape is (2, 1, 2, 1). Try to use negative indices as the argument of `torch.unsqueeze()`.\n",
    "3. Turn the tensor back to its original shape (2, 2) by using `torch.squeeze()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b671e74f22171ec8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-19T07:15:03.127711Z",
     "start_time": "2024-09-19T07:15:03.124690Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 1, 2])\n",
      "torch.Size([2, 1, 2, 1])\n",
      "torch.Size([2, 2])\n"
     ]
    }
   ],
   "source": [
    "## 1: Create a tensor of size (2, 2). Unsqueeze it so that its final shape is (2, 1, 2)\n",
    "rand_t = torch.rand((2,2))\n",
    "rand_t = rand_t.unsqueeze(1)\n",
    "print(rand_t.shape)\n",
    "## 2: Add an additional dimension to the tensor so that its shape is (2, 1, 2, 1). Use negative indices\n",
    "rand_t = rand_t.unsqueeze(3)\n",
    "print(rand_t.shape)\n",
    "## 3: Turn the tensor back to shape (2, 2)\n",
    "rand_t = rand_t.squeeze()\n",
    "print(rand_t.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e93229b6fa5c1e07",
   "metadata": {},
   "source": [
    "## Concatenate and stack\n",
    "\n",
    "If you have two tensors of compatible sizes, you can merge them into a unique tensor along one of their axes.\n",
    "In order to get some intuition, think about having 2 2-dimensional tensors of size (3, 4). You can merge them along the first axis and get the final shape be (6, 4), or you can merge them along the second axis and get the final shape to be (3, 8), or you can go in 3D stacking one over the other (along the z-axis) and get a shape of (2, 3, 4). \n",
    "\n",
    "This is precisely what [`torch.concat`](https://pytorch.org/docs/stable/generated/torch.cat.html#torch.cat) (also called `.cat`) and [`torch.stack`](https://pytorch.org/docs/stable/generated/torch.stack) do. \n",
    "You should already be familiar with NumPy `axis` attribute. In PyTorch it is called `dim`. If you try using `axis` instead of `dim`, PyTorch allows you to do so. Though it is not recommended, since it is not written in the official documentation.\n",
    "\n",
    "1. Concat $v$ and $w$ along the first dimension. Check that the final shape is (6, 4).\n",
    "2. Concat $v$ and $w$ along the second dimension. Check that the final shape is (3, 8).\n",
    "3. Concat $v$ and $w$ along a new dimension. Check that the final shape is (2, 3, 4)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e9399001d3b3efa4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-19T08:16:40.985443Z",
     "start_time": "2024-09-19T08:16:40.982553Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[9, 2, 6, 8],\n",
      "        [2, 8, 2, 1],\n",
      "        [0, 0, 6, 5]])\n",
      "tensor([[0, 6, 9, 2],\n",
      "        [4, 2, 0, 2],\n",
      "        [3, 3, 1, 6]])\n",
      "tensor([[9, 2, 6, 8],\n",
      "        [2, 8, 2, 1],\n",
      "        [0, 0, 6, 5],\n",
      "        [0, 6, 9, 2],\n",
      "        [4, 2, 0, 2],\n",
      "        [3, 3, 1, 6]])\n",
      "tensor([[9, 2, 6, 8, 0, 6, 9, 2],\n",
      "        [2, 8, 2, 1, 4, 2, 0, 2],\n",
      "        [0, 0, 6, 5, 3, 3, 1, 6]])\n",
      "tensor([[[9, 2, 6, 8],\n",
      "         [2, 8, 2, 1],\n",
      "         [0, 0, 6, 5]],\n",
      "\n",
      "        [[0, 6, 9, 2],\n",
      "         [4, 2, 0, 2],\n",
      "         [3, 3, 1, 6]]])\n"
     ]
    }
   ],
   "source": [
    "v = torch.randint(0, 10, (3,4))\n",
    "w = torch.randint(0, 10, (3,4))\n",
    "print(v)\n",
    "print(w)\n",
    "## 1: concat along first dimension.\n",
    "print(torch.concat([v,w]))\n",
    "## 2: concat along second dimension.\n",
    "print(torch.concat([v,w], dim=1))\n",
    "## 3: concat along new dimension.\n",
    "print(torch.stack([v,w]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2642bbd9-27d0-40f7-8cfd-d80bdfc54d0f",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Reshape and View\n",
    "\n",
    "PyTorch lets you reshape your tensors, by keeping the same data, but re-arranging its dimensions.\n",
    "\n",
    "Create a random vector of size (2, 3, 4), and make a new vector of size (6, 4) using [``torch.reshape``](https://docs.pytorch.org/docs/stable/generated/torch.Tensor.reshape.html) and [``torch.view``](https://www.geeksforgeeks.org/python/how-does-the-view-method-work-in-python-pytorch/).\n",
    "\n",
    "- `torch.reshape` works on all vectors, but it might be less efficient when working on contiguous data.\n",
    "- `torch.view` only works on contiguous data (see [``torch.is_contiguous``](https://docs.pytorch.org/docs/stable/generated/torch.Tensor.is_contiguous.html)), but it is more efficient.\n",
    "\n",
    "In general, ``torch.reshape`` is the safest option to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2fe5b970-1d17-4bca-994d-7562b05e2dae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 3,  1,  4, 10],\n",
      "         [ 7,  2,  9,  9],\n",
      "         [ 2,  0,  1,  1]],\n",
      "\n",
      "        [[ 5,  1,  0,  4],\n",
      "         [ 4,  0,  0, 10],\n",
      "         [ 8,  8,  8,  5]]])\n",
      "tensor([[ 3,  1,  4, 10],\n",
      "        [ 7,  2,  9,  9],\n",
      "        [ 2,  0,  1,  1],\n",
      "        [ 5,  1,  0,  4],\n",
      "        [ 4,  0,  0, 10],\n",
      "        [ 8,  8,  8,  5]])\n",
      "tensor([[ 3,  1,  4, 10],\n",
      "        [ 7,  2,  9,  9],\n",
      "        [ 2,  0,  1,  1],\n",
      "        [ 5,  1,  0,  4],\n",
      "        [ 4,  0,  0, 10],\n",
      "        [ 8,  8,  8,  5]])\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "## 1: create a random tensor of size (2, 3, 4)\n",
    "v = torch.randint(0,11,(2,3,4))\n",
    "print(v)\n",
    "## 2: reshape it so that its size is (6, 4) using torch.reshape\n",
    "# Is v altered by reshape?\n",
    "print(v.reshape(6,4))\n",
    "## 3: reshape v so that its size is (6, 4) using torch.view\n",
    "# Is v altered by view?\n",
    "print(v.view(6,4))\n",
    "## 4: as a final step, try to make a tensor not contiguous: e.g., permuting its dimensions\n",
    "v = torch.rand(2, 3, 4)\n",
    "# Permute v's dimensions by using torch.permute, so that the final shape is (3, 2, 4). Do it inplace.\n",
    "v = v.permute((1,0,2))\n",
    "# Make sure that v is not contiguous anymore.\n",
    "print(v.is_contiguous())\n",
    "# print(v.view(6, 4)) would yield an error."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7695c739ef39b4bb",
   "metadata": {},
   "source": [
    "## Broadcasting\n",
    "\n",
    "Same as in NumPy, also PyTorch tensors allow [broadcasting](https://pytorch.org/docs/stable/notes/broadcasting.html).\n",
    "When performing element-wise operations (like sums) on two tensors of mismatching sizes, the smaller tensor can adapt to the size of the larger tensor in case these simple rules apply:\n",
    "\n",
    "- Each tensor has at least one dimension.\n",
    "- When iterating over the dimension sizes, starting at the trailing (right-most) dimension, the dimension sizes must be\n",
    "    -  equal\n",
    "    -  one of them is 1\n",
    "    -  one of them does not exist.\n",
    "\n",
    "Let us see an example:\n",
    "\n",
    "Assume you have $v = [[1, 2, 3], [4, 5, 6]]$ shape (2, 3) and $w=[3, 2, 1]$ shape (3). If we want to perform $v + w$ (element by element sum), it is clear that the dimensions don't match, but with the help of broadcasting we can still do it: $w$ is simply enlarged to reach size (2, 3) by copying itself twice on the first axis. Then, it is possible to perform element by element sum $v+w$.\n",
    "\n",
    "Let's put broadcasting in practice:\n",
    "\n",
    "1. Perform the above described example $v+w$ using tensors, check that the result size is (2, 3) and that numbers add up.\n",
    "2. $r = [[1, 2], [3, 4], [5, 6]]$ and $l=[1, 2, 3]$. Compute $r + l$. It should raise errors. Why?\n",
    "3. Adjust the size of $l$ in example 2 so that the sum works. What size should $l$ have in order for broadcasting to work on $r + l$?\n",
    "4. Create random integers tensors $s$ of size (2, 1, 3, 1) and $t$ of size (1, 3, 1, 3). Does broadcasting work here in order to compute $s+t$? In case it does, predict the final shape of the result. \n",
    " \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "25c1ff851e016878",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-19T08:58:04.389094Z",
     "start_time": "2024-09-19T08:58:04.387183Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[4, 4, 4],\n",
      "        [7, 7, 7]])\n",
      "tensor([[1],\n",
      "        [2],\n",
      "        [3]])\n",
      "tensor([[2, 3],\n",
      "        [5, 6],\n",
      "        [8, 9]])\n",
      "torch.Size([2, 3, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "v = torch.arange(1,7).reshape(2,3)\n",
    "r = torch.arange(1,7).reshape(3,2)\n",
    "l = torch.arange(1,4)\n",
    "w = torch.arange(3,0,-1)\n",
    "## 1: compute v + w\n",
    "print(v+w)\n",
    "## 2: compute r + l. It doesn't work, why?\n",
    "#r+l\n",
    "## 3: adjust the size of l, and compute r + l\n",
    "l = l.reshape(3,1)\n",
    "print(l)\n",
    "print(r+l)\n",
    "## 4: compute s + t\n",
    "s = torch.randint(0,11,(2,1,3,1))\n",
    "t = torch.randint(0,11,(1,3,1,3))\n",
    "# shape (2,3,3,3)\n",
    "print((s+t).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e5ea76fcf50b553",
   "metadata": {},
   "source": [
    "## PyTorch functions\n",
    "\n",
    "In this section we are going to learn the basic functions of PyTorch.\n",
    "\n",
    "### Mean, min, max, sum ...\n",
    "\n",
    "These functions are quite self-explanatory, and they work the same way as in NumPy. The only detail we ought to pay attention to is the axis we want to perform the function along (in NumPy it was called `axis`, in PyTorch `dim`).\n",
    "\n",
    "Create a random tensor $v$ of ints of size (3, 2, 4) and print it.\n",
    "\n",
    "In order to be sure you have understood what is going on, try to predict the result and then check that your prediction is wrong/correct.\n",
    "\n",
    "1. Compute the min value in the entire tensor.\n",
    "2. Compute the max value along axis 0.\n",
    "3. Compute the min along axis 1.\n",
    "4. Multi-dimensional axes: take the sum over axes (0, 1). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6212dd7b00b8bc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 2,  5,  0,  2],\n",
      "         [ 9,  4,  3,  5]],\n",
      "\n",
      "        [[ 3,  9,  2,  3],\n",
      "         [ 5,  7,  3,  8]],\n",
      "\n",
      "        [[10,  1,  7,  2],\n",
      "         [10,  3,  0,  1]]])\n"
     ]
    }
   ],
   "source": [
    "# Create v of shape (3, 2, 4)\n",
    "v = torch.randint(0,11,(3,2,4))\n",
    "print(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "de343d48896069b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-19T09:11:40.284320Z",
     "start_time": "2024-09-19T09:11:40.281917Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0)\n",
      "torch.return_types.max(\n",
      "values=tensor([[10,  9,  7,  3],\n",
      "        [10,  7,  3,  8]]),\n",
      "indices=tensor([[2, 1, 2, 1],\n",
      "        [2, 1, 0, 1]]))\n",
      "torch.Size([2, 4])\n",
      "torch.return_types.min(\n",
      "values=tensor([[ 2,  4,  0,  2],\n",
      "        [ 3,  7,  2,  3],\n",
      "        [10,  1,  0,  1]]),\n",
      "indices=tensor([[0, 1, 0, 0],\n",
      "        [0, 1, 0, 0],\n",
      "        [0, 0, 1, 1]]))\n",
      "tensor([39, 29, 15, 21])\n"
     ]
    }
   ],
   "source": [
    "## 1: Compute the min value of v.\n",
    "print(v.min())\n",
    "## 2: Compute the max along axis 0.\n",
    "print(v.max(0))\n",
    "print(v.max(0)[0].shape)\n",
    "## 3: Compute the min along axis 1.\n",
    "print(v.min(1)) # 6,9,8,1 | 2,6,8,3 | 5,10,3,8\n",
    "## 4: Compute the sum over axes (0, 1)\n",
    "print(v.sum((0,1)))  # [19,34,20,22] (4,)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a68f8062d06c1ada",
   "metadata": {},
   "source": [
    "### [`torch.dot`](https://docs.pytorch.org/docs/stable/generated/torch.dot.html#torch.dot), [`torch.matmul`](https://docs.pytorch.org/docs/stable/generated/torch.matmul), *\n",
    "\n",
    "Unlike NumPy, Torch has a stricter policy on these operands:\n",
    "\n",
    "- `*`: is the Hadamard product. I.e., element-wise product.\n",
    "- [`torch.dot`](https://docs.pytorch.org/docs/stable/generated/torch.dot.html#torch.dot): only used to compute the dot product of two 1-dimensional tensors. Remember how confusing the dot product between multi-dimension NumPy vectors is (see Exercise 1)? PyTorch avoids this issue by simply forbidding the dimension of the input tensors to be greater than 1.\n",
    "- [`torch.matmul`](https://docs.pytorch.org/docs/stable/generated/torch.matmul): or its alias `@` computes the matrix product. Can be used for larger than 2-dimensional tensors (it applies broadcasting, as much as in NumPy). Notice that the complexity of multiplying two $n\\times n$ matrices is $O(n^3)$. We will take advantage of its relatively high time-complexity in order to show how much faster are GPUs with respect to CPUs later on in the notebook.\n",
    "\n",
    "1. Create two random integer tensors $A$ and $B$ of compatible sizes and perform their Hadamard product (element by element product). Try these sizes (predict whether they work or not):\n",
    "    - $A$ size (3, 4), $B$ size (3, 4).\n",
    "    - $A$ size (3, 4), $B$ size (4, 4).\n",
    "    - $A$ size (3, 4), $B$ size (1, 4).\n",
    "2. Create two random 1-dimensional tensors $v, w$ and compute their dot product. If you can use multiple ways to compute it, check that indeed they return the same value.\n",
    "3. Create $C$ of size (3, 4) and $D$ of size (4, 3). Compute the matrix product. Are the sizes compatible?\n",
    "4. Create $E$ of size (3, 3) and $F$ of size (4, 3). Compute the matrix product. Are the sizes compatible? If not, use the transpose operator [`torch.t()`](https://docs.pytorch.org/docs/stable/generated/torch.t.html#torch.t) to adjust the dimensions of one of the two matrices and compute the matrix product.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d3d65a6ea3ebcf42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[10, 12, 25,  6],\n",
      "        [18,  1,  6, 24],\n",
      "        [60,  5, 18, 72]])\n",
      "tensor([[24, 12,  2, 18],\n",
      "        [20, 20,  7, 12],\n",
      "        [ 8, 18,  0, 21]])\n",
      "tensor(10)\n",
      "tensor([[189,  70, 126],\n",
      "        [235,  78, 158],\n",
      "        [ 88,  30,  71]])\n",
      "tensor([[101, 101, 141, 128],\n",
      "        [ 19,  16,  24,  22],\n",
      "        [ 90,  65, 100, 100]])\n"
     ]
    }
   ],
   "source": [
    "## 1: Create A, B and perform hadamard product\n",
    "# A (3,4), B (3,4) should work\n",
    "a = torch.randint(0,11,(3,4))\n",
    "b = torch.randint(0,11,(3,4))\n",
    "print(a*b)\n",
    "# A (3,4), B (4,4) does not work\n",
    "a = torch.randint(0,11,(3,4))\n",
    "b = torch.randint(0,11,(4,4))\n",
    "#print(a*b)\n",
    "# A (3,4), B (1,4) should work\n",
    "a = torch.randint(0,11,(3,4))\n",
    "b = torch.randint(0,11,(1,4))\n",
    "print(a*b)\n",
    "## 2: Create 1-dimensional tensors v, w and compute their dot product.\n",
    "v = torch.tensor([1,2,3])\n",
    "w = torch.tensor([3,2,1])\n",
    "print(torch.dot(v,w))\n",
    "## 3: Compute matrix product of C and D.\n",
    "c = torch.randint(1,11,(3,4))\n",
    "d = torch.randint(1,11,(4,3))\n",
    "print(c @ d)\n",
    "## 4: adjust dimensions using .T, and compute the matrix product E @ F\n",
    "e = torch.randint(1,11,(3,3))\n",
    "f = torch.randint(1,11,(4,3))\n",
    "print(e @ f.t())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9176dfb298f4b9e",
   "metadata": {},
   "source": [
    "## Gradients\n",
    "\n",
    "One of the useful features of PyTorch (that NumPy doesn't have) is that it is possible to compute automatically the gradient of functions. \n",
    "As you will see, the gradient of a function is one of the key ingredients of the backpropagation algorithm, used to train neural nets.\n",
    "This is also one of the reason why PyTorch is so ubiquitous to neural nets applications.\n",
    "\n",
    "Assume we have tensor $x = [2], y = [2]$. We have $z = 2x^2 + 3y = [14]$.\n",
    "\n",
    "We know that $\\frac{\\delta z}{\\delta x} = 4x$, $\\frac{\\delta z}{\\delta y} = 3$. Since we are evaluating the point $x=2, y=2$, we get that the gradient is (8, 3). The gradients are going to be stored in `x.grad` and `y.grad` if we specify the option `requires_grad=True`. We can let PyTorch compute the gradients by invoking `z.backward()`. Check that indeed `x.grad` and `y.grad` hold the desired values.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2e3e254da08cb300",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-19T10:25:06.967129Z",
     "start_time": "2024-09-19T10:25:06.961072Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([8.], dtype=torch.float64)\n",
      "tensor([3.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([2], dtype=torch.float64, requires_grad=True)\n",
    "y = torch.tensor([2], dtype=torch.float64, requires_grad=True)\n",
    "z = 2 * x*x + 3 * y\n",
    "z.backward()\n",
    "print(x.grad)\n",
    "print(y.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0f3648bc606d705",
   "metadata": {},
   "source": [
    "1. Create tensors $s = [1]$ and $t = [1]$, define a new tensor $w = 5s + 6$ and compute its gradient. What is the gradient associated to $t$? (Notice that $w$ does not depend on $t$). \n",
    "2. What happens if we try to define an integer tensor with `requires_grad=True`?\n",
    "3. What happens if we call `numpy()` on a tensor that has `requires_grad=True`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "54c046fde0ee306e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-19T12:03:47.093944Z",
     "start_time": "2024-09-19T12:03:47.091851Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([5.], dtype=torch.float64)\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "s = torch.tensor([1], dtype=torch.float64, requires_grad=True)\n",
    "t = torch.tensor([1], dtype=torch.float64, requires_grad=True)\n",
    "## 1: gradient of t for w = 5s + 6.\n",
    "w = 5 * s + 6\n",
    "w.backward()\n",
    "print(s.grad)\n",
    "print(t.grad)\n",
    "## 2: integer tensor with requires_grad.\n",
    "#l = torch.tensor([1], dtype=torch.int64, requires_grad=True)\n",
    "## 3: compute .numpy() of a tensor with requires_grad.\n",
    "# s.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3834bc4e",
   "metadata": {},
   "source": [
    "In this section we point out a very important feature of gradients, namely that they are *cumulative*! In order to see what does that mean, let's see in practice the example that was given in class:\n",
    "\n",
    "1. Create tensors $x=[2], y=[3]$ (with flag `requires_grad=True`).\n",
    "2. Compute $z = x * x + y$ and perform the backward pass.\n",
    "3. Check that the gradients are as expected: $\\frac{\\delta z}{\\delta x}=2x=4$, $\\frac{\\delta z}{\\delta y} = 1$.\n",
    "4. Compute $g = xy + 3x$ and perform che backward pass.\n",
    "5. Check out the gradients: $\\frac{\\delta g}{\\delta x}=y + 3=6$, $\\frac{\\delta g}{\\delta y} = x = 2$.\n",
    "6. Do you see the expected value? Can you explain why? (hint: gradients are *cumulative*).\n",
    "7. In order to fix this potential issue, use [`torch.zero_grad()`](https://docs.pytorch.org/docs/stable/generated/torch.optim.Optimizer.zero_grad.html) in between the computation of $z$ and $g$. Do you observe the expected gradient now?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0e33d42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4.)\n",
      "tensor(1.)\n",
      "tensor(10.)\n",
      "tensor(3.)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "element 0 of tensors does not require grad and does not have a grad_fn",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[20]\u001b[39m\u001b[32m, line 19\u001b[39m\n\u001b[32m     17\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n\u001b[32m     18\u001b[39m     z = x * x + y\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m     \u001b[43mz\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     20\u001b[39m     \u001b[38;5;66;03m## 3: check out gradients of x, y.\u001b[39;00m\n\u001b[32m     21\u001b[39m     \u001b[38;5;28mprint\u001b[39m(x.grad)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\pauls\\code\\py_envs\\dllab\\Lib\\site-packages\\torch\\_tensor.py:647\u001b[39m, in \u001b[36mTensor.backward\u001b[39m\u001b[34m(self, gradient, retain_graph, create_graph, inputs)\u001b[39m\n\u001b[32m    637\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    638\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[32m    639\u001b[39m         Tensor.backward,\n\u001b[32m    640\u001b[39m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[32m   (...)\u001b[39m\u001b[32m    645\u001b[39m         inputs=inputs,\n\u001b[32m    646\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m647\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mautograd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    648\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs\u001b[49m\n\u001b[32m    649\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\pauls\\code\\py_envs\\dllab\\Lib\\site-packages\\torch\\autograd\\__init__.py:354\u001b[39m, in \u001b[36mbackward\u001b[39m\u001b[34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[39m\n\u001b[32m    349\u001b[39m     retain_graph = create_graph\n\u001b[32m    351\u001b[39m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[32m    352\u001b[39m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[32m    353\u001b[39m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m354\u001b[39m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    355\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    356\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    357\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    358\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    359\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs_tuple\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    360\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    361\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    362\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\pauls\\code\\py_envs\\dllab\\Lib\\site-packages\\torch\\autograd\\graph.py:829\u001b[39m, in \u001b[36m_engine_run_backward\u001b[39m\u001b[34m(t_outputs, *args, **kwargs)\u001b[39m\n\u001b[32m    827\u001b[39m     unregister_hooks = _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[32m    828\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m829\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_execution_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[32m    830\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    831\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[32m    832\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    833\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[31mRuntimeError\u001b[39m: element 0 of tensors does not require grad and does not have a grad_fn"
     ]
    }
   ],
   "source": [
    "## 1: create x, y.\n",
    "x = torch.tensor(2.0, requires_grad=True)\n",
    "y = torch.tensor(3.0, requires_grad=True)\n",
    "## 2: compute z.\n",
    "z = x * x + y\n",
    "z.backward()\n",
    "## 3: check out gradients of x, y.\n",
    "print(x.grad)\n",
    "print(y.grad)\n",
    "## 4: compute g.\n",
    "g = x*y + 3*x\n",
    "g.backward()\n",
    "## 5: check out gradients of x, y\n",
    "print(x.grad)\n",
    "print(y.grad)\n",
    "## 7: Repeat 1-5 using torch.zero_grad()\n",
    "## 1: create x, y.\n",
    "x = torch.tensor(2.0, requires_grad=True)\n",
    "y = torch.tensor(3.0, requires_grad=True)\n",
    "## 2: compute z.\n",
    "z = x * x + y\n",
    "z.backward()\n",
    "## 3: check out gradients of x, y.\n",
    "print(x.grad)\n",
    "print(y.grad)\n",
    "x = torch.tensor(2.0, requires_grad=True)\n",
    "y = torch.tensor(3.0, requires_grad=True)\n",
    "## 4: compute g.\n",
    "g = x*y + 3*x\n",
    "g.backward()\n",
    "## 5: check out gradients of x, y\n",
    "print(x.grad)\n",
    "print(y.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16a5b2e2-b0ac-4638-b5da-441b584ce139",
   "metadata": {},
   "source": [
    "## Device (GPU vs CPU)\n",
    "\n",
    "In this section we will learn how do computation using the GPU instead of the CPU: notice that this is the main reason why, in Deep Learning applications, PyTorch is used over NumPy.\n",
    "\n",
    "By default, tensors are accessed by the CPU. You can check it easily using the [`.device()`](https://pytorch.org/docs/stable/tensor_attributes.html#torch.device) method.\n",
    "1) Create an identity matrix of size (4, 4) and access its device attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e3a205fdbd7b65c9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-18T20:17:23.060931Z",
     "start_time": "2024-09-18T20:17:23.055769Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "## 1: see .device of a matrix\n",
    "\n",
    "v = torch.eye(4)  # create a tensor\n",
    "print(v.device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "170a51fb-4d16-4362-8dc1-87329f29fe58",
   "metadata": {},
   "source": [
    "Hence, every time we want to use the GPU, we need to explicitly move the tensors to the desired device. Careful here: your laptop doesn't necessarily have a dedicated GPU. And, even if it has one, it might not be compatible with CUDA (the NVIDIA interface that allows computations to be performed on the GPU).\n",
    "\n",
    "You can check if CUDA is available on your machine by simply using [`cuda.is_available()`](https://pytorch.org/docs/stable/generated/torch.cuda.is_available.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "40633cabf32ec826",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-18T20:08:57.159307Z",
     "start_time": "2024-09-18T20:08:57.154986Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0d81546-7b64-4bab-a05a-82626fe27b69",
   "metadata": {},
   "source": [
    "If the above returns False, it could be either because you didn't install correctly CUDA, or because you laptop doesn't have a GPU compatible with it. \n",
    "If you have a MacBook with Apple Silicon processors, you can still use the device `mps`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "34009eeefef2b8a7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-18T20:12:06.271423Z",
     "start_time": "2024-09-18T20:12:06.267589Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For mac M1/2/3/* users\n",
    "torch.backends.mps.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e4c16e3-1c54-49e9-8130-1d84dc63847c",
   "metadata": {},
   "source": [
    "We can set the device to one of these three options:\n",
    "- `cuda` (if you have a NVIDIA graphics card). Might be `cuda:0` etc if you have more than one.\n",
    "- `mps` (if you have a MacBook with M1/2/3/* processor)\n",
    "- `cpu` otherwise\n",
    "\n",
    "If your laptop doesn't have any of the above-mentioned devices apart from the CPU, you can use Kaggle's notebooks: they offer free hours of GPU per week (they count the hours the kernel is running, not if you are actually using the notebook. Hence, remember to shut the kernel down when you don't use it!!!)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed3bcc00-317e-43ed-8a30-638fddbf43dd",
   "metadata": {},
   "source": [
    "If you are using Kaggle platform for your projects (we recommend you to do that), you have at your disposal 30h/week of free GPUs: in order to activate it, you need to open a notebook, go to settings -> accelerator and you can select a GPU from there. If the GPU options are non-clickable, it is because you have to verify you account using your phone number. Go to home -> your picture (top right border) -> settings -> phone verification. Before the options become actually clickable you will need to wait a few minutes (<5')."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2dc0d82333ea4030",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-18T20:17:26.711323Z",
     "start_time": "2024-09-18T20:17:26.707268Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'mps' if torch.backends.mps.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "299aa2b1-a6de-47d4-8cff-2c37221322e8",
   "metadata": {},
   "source": [
    "Finally, move the tensor `v` you created earlier to the most convenient device. Use function [`.to`](https://pytorch.org/docs/stable/generated/torch.Tensor.to.html). Careful: is it an in-place method? Check that the device is indeed correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9c331d995b0e7c26",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-18T20:24:40.156801Z",
     "start_time": "2024-09-18T20:24:40.153872Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "# Move vector v to the correct device. Check it is indeed on the desired device.\n",
    "v = v.to(device)\n",
    "print(v.device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea0b643e-a116-4c28-962c-a237ff28183f",
   "metadata": {},
   "source": [
    "You can also create a tensor and send it directly to the correct device. \n",
    "1. Create a tensor of ones of size (3, 3) and specify in its constructor the `device` attribute. Check that, indeed, the tensor has been initialized with the correct device."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2f9247113e7f4981",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-19T06:49:34.057350Z",
     "start_time": "2024-09-19T06:49:34.051445Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 1: Create a tensor and initialize it to the correct device.\n",
    "x = torch.ones((3,3), device=device)\n",
    "x.device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4db0572c-b28c-4616-b290-de2400adf0d4",
   "metadata": {},
   "source": [
    "### GPUs vs CPUs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c17c95ca-30b9-456b-9b0c-8f860f78d4cb",
   "metadata": {},
   "source": [
    "Now, we prove empirically that GPUs are much faster than CPUs at doing large calculations.\n",
    "\n",
    "Create large tensors $G, H$ both of size (15000, 15000). Take their matrix product and measure how long it takes (use [`%%time`](https://ipython.readthedocs.io/en/9.2.0/interactive/magics.html) cell magic notebook function)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1331573f-44b7-47b9-8277-caf8b6ea8979",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-18T20:17:26.711323Z",
     "start_time": "2024-09-18T20:17:26.707268Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='mps')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'mps' if torch.backends.mps.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cf9337e5-7001-40b6-b27b-a9ee4571b8d6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-19T09:49:37.404396Z",
     "start_time": "2024-09-19T09:49:35.677903Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create E and F\n",
    "G = torch.rand(15000, 15000)\n",
    "H = torch.rand(15000, 15000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9873259f-7245-49e1-b906-982a9d08c6ec",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-19T09:49:55.733265Z",
     "start_time": "2024-09-19T09:49:45.723855Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7.42 s, sys: 460 ms, total: 7.88 s\n",
      "Wall time: 4.22 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[3726.7639, 3756.2234, 3699.6274,  ..., 3721.4380, 3738.4131,\n",
       "         3754.0791],\n",
       "        [3755.6550, 3777.7593, 3741.3372,  ..., 3755.9939, 3770.7937,\n",
       "         3747.3943],\n",
       "        [3767.4851, 3801.6426, 3752.6885,  ..., 3770.9099, 3765.2354,\n",
       "         3759.9216],\n",
       "        ...,\n",
       "        [3761.4927, 3790.4978, 3766.2434,  ..., 3771.4724, 3783.7256,\n",
       "         3779.7422],\n",
       "        [3765.3115, 3799.5425, 3747.0039,  ..., 3755.6519, 3781.7246,\n",
       "         3793.4346],\n",
       "        [3757.9209, 3775.9148, 3742.3926,  ..., 3752.0540, 3760.3030,\n",
       "         3760.2754]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "G @ H"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3459c395-3655-482d-b647-7c373dac0a0a",
   "metadata": {},
   "source": [
    "Move $E$ and $F$ to the most convenient device at your disposal (different from CPU, if possible), and compute the same matrix product."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e77b61a4-dd2a-4b9f-adef-1675110f4309",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-19T09:50:02.144090Z",
     "start_time": "2024-09-19T09:50:01.448426Z"
    }
   },
   "outputs": [],
   "source": [
    "# Move the tensors to GPU in another cell, so that the time is not counted.\n",
    "G = G.to(device)\n",
    "H = H.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e3841d73-fd93-478e-bf5b-9bda1c0a1823",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-19T09:50:05.795896Z",
     "start_time": "2024-09-19T09:50:04.017497Z"
    },
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 21 ms, sys: 26.7 ms, total: 47.7 ms\n",
      "Wall time: 163 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[3726.7639, 3756.2234, 3699.6274,  ..., 3721.4304, 3738.4143,\n",
       "         3754.0664],\n",
       "        [3755.6550, 3777.7593, 3741.3372,  ..., 3755.9897, 3770.8015,\n",
       "         3747.3979],\n",
       "        [3767.4851, 3801.6426, 3752.6885,  ..., 3770.9121, 3765.2329,\n",
       "         3759.9214],\n",
       "        ...,\n",
       "        [3761.4927, 3790.4978, 3766.2434,  ..., 3771.4734, 3783.7253,\n",
       "         3779.7429],\n",
       "        [3765.3115, 3799.5425, 3747.0039,  ..., 3755.6516, 3781.7271,\n",
       "         3793.4272],\n",
       "        [3757.9209, 3775.9148, 3742.3926,  ..., 3752.0532, 3760.2930,\n",
       "         3760.2812]], device='mps:0')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "G @ H"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e9a0105-a907-4518-969f-71a39d70ceae",
   "metadata": {},
   "source": [
    "Side note: on my laptop (MacBook) I noticed a performance improvement by $\\approx\\times 10$. On Kaggle the performance improvement is much larger (from >20'' to <<1').\n",
    "\n",
    "At the end of this task, if you are using Kaggle, remember to shut down your kernel (or Kaggle will continue charging you GPU time)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "389dd9ec-0480-4d6a-9cfe-e9a9309868f4",
   "metadata": {},
   "source": [
    "# A super quick introduction to pandas\n",
    "\n",
    "[Pandas](https://pandas.pydata.org/) is the equivalent of a Python database (but it is also a \"data analysis and manipulation tool\"). Or Python's version of Excel, if you prefer.\n",
    "\n",
    "Install it in your environment (using your IDE's GUI, or by typing in your command line `conda install pandas`).\n",
    "\n",
    "Next, we will see the most basic usage of pandas: making queries and modifying your data. Keep in mind that pandas does much more than that: see this simple [cheatsheet](https://pandas.pydata.org/docs/user_guide/10min.html) for reference.\n",
    "\n",
    "It is best practice, in pandas, to use the shortcut `pd` on import."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f1d77ba6-2672-429c-a680-1fb68c788527",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2164af8-b9ac-4328-8156-866860c4b9d6",
   "metadata": {},
   "source": [
    "A table in pandas is called `pd.DataFrame`. Single columns, instead, are called `pd.Series` (a `pd.Series` is the pandas equivalent of a `torch.tensor` or `np.array`).\n",
    "You can create a table using some data in a dictionary, or importing it from any well-formatted file (see, e.g., [`pd.read_csv`](https://pandas.pydata.org/docs/reference/api/pandas.read_csv.html#pandas.read_csv))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9f21b677-218f-4034-a91d-6d953d72411b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Department</th>\n",
       "      <th>Salary</th>\n",
       "      <th>Years_at_Company</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>a</th>\n",
       "      <td>Alice</td>\n",
       "      <td>HR</td>\n",
       "      <td>50000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b</th>\n",
       "      <td>Bob</td>\n",
       "      <td>IT</td>\n",
       "      <td>60000</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c</th>\n",
       "      <td>Charlie</td>\n",
       "      <td>Finance</td>\n",
       "      <td>55000</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d</th>\n",
       "      <td>Diana</td>\n",
       "      <td>IT</td>\n",
       "      <td>65000</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>e</th>\n",
       "      <td>Ethan</td>\n",
       "      <td>HR</td>\n",
       "      <td>52000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Name Department  Salary  Years_at_Company\n",
       "a    Alice         HR   50000                 2\n",
       "b      Bob         IT   60000                 5\n",
       "c  Charlie    Finance   55000                 3\n",
       "d    Diana         IT   65000                 7\n",
       "e    Ethan         HR   52000                 1"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = {\n",
    "    \"Name\": [\"Alice\", \"Bob\", \"Charlie\", \"Diana\", \"Ethan\"],\n",
    "    \"Department\": [\"HR\", \"IT\", \"Finance\", \"IT\", \"HR\"],\n",
    "    \"Salary\": [50000, 60000, 55000, 65000, 52000],\n",
    "    \"Years_at_Company\": [2, 5, 3, 7, 1],\n",
    "}\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame(data, index=['a', 'b', 'c', 'd', 'e'])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1447feb-ee8b-4067-932c-4e1d0141b511",
   "metadata": {},
   "source": [
    "As you see, the data is nicely displayed in a table. The additional column (without a title) is the index: namely, the name of every row. By default it is an increasing number, but you can change it to be anything (in our case, we used letters)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c24bb5b6-ec08-4851-82ac-cda6685997eb",
   "metadata": {},
   "source": [
    "## Queries\n",
    "\n",
    "You can select columns using the usual `[]` notation (this returns a `pd.Series`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8b6afc30-fb41-497d-ab56-afab06bc413a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a         HR\n",
       "b         IT\n",
       "c    Finance\n",
       "d         IT\n",
       "e         HR\n",
       "Name: Department, dtype: object"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Department']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95bd8fbf-b79c-4070-99fe-333e11ebae4b",
   "metadata": {},
   "source": [
    "Or, multiple columns with the ``[[]]`` notation (this returns a `pd.DataFrame`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "46b0cd24-97cc-4bc1-9d3c-2fe6493f6734",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Department</th>\n",
       "      <th>Salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>a</th>\n",
       "      <td>HR</td>\n",
       "      <td>50000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b</th>\n",
       "      <td>IT</td>\n",
       "      <td>60000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c</th>\n",
       "      <td>Finance</td>\n",
       "      <td>55000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d</th>\n",
       "      <td>IT</td>\n",
       "      <td>65000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>e</th>\n",
       "      <td>HR</td>\n",
       "      <td>52000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Department  Salary\n",
       "a         HR   50000\n",
       "b         IT   60000\n",
       "c    Finance   55000\n",
       "d         IT   65000\n",
       "e         HR   52000"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['Department','Salary']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fade294-2afe-4059-a2fb-16390f44e1b8",
   "metadata": {},
   "source": [
    "You can select rows (as much as in SQL) according to any condition: it is enough to create a boolean vector with the rows to select, and use the following syntax:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b66a888f-cbc6-4599-8e02-c8868c591356",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Department</th>\n",
       "      <th>Salary</th>\n",
       "      <th>Years_at_Company</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>a</th>\n",
       "      <td>Alice</td>\n",
       "      <td>HR</td>\n",
       "      <td>50000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b</th>\n",
       "      <td>Bob</td>\n",
       "      <td>IT</td>\n",
       "      <td>60000</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>e</th>\n",
       "      <td>Ethan</td>\n",
       "      <td>HR</td>\n",
       "      <td>52000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Name Department  Salary  Years_at_Company\n",
       "a  Alice         HR   50000                 2\n",
       "b    Bob         IT   60000                 5\n",
       "e  Ethan         HR   52000                 1"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[[True, True, False, False, True]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea5d6833-da9a-49a8-ad43-4c24afc3b24d",
   "metadata": {},
   "source": [
    "You can create boolean vectors according to any condition using element-wise boolean operators:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a1fbdd22-b7b1-4af8-adb1-8db4abcd2eaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a    False\n",
       "b     True\n",
       "c     True\n",
       "d     True\n",
       "e    False\n",
       "Name: Salary, dtype: bool"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Salary'] > 53000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beac106b-8f91-45a0-a48e-bb0c5808caf7",
   "metadata": {},
   "source": [
    "Putting everything together, write a query to select the names of the people that earn more than 53000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "93f9ede8-9df5-4dd8-a993-802b28c7a28e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Department</th>\n",
       "      <th>Salary</th>\n",
       "      <th>Years_at_Company</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>a</th>\n",
       "      <td>Alice</td>\n",
       "      <td>HR</td>\n",
       "      <td>50000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b</th>\n",
       "      <td>Bob</td>\n",
       "      <td>IT</td>\n",
       "      <td>60000</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c</th>\n",
       "      <td>Charlie</td>\n",
       "      <td>Finance</td>\n",
       "      <td>55000</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d</th>\n",
       "      <td>Diana</td>\n",
       "      <td>IT</td>\n",
       "      <td>65000</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>e</th>\n",
       "      <td>Ethan</td>\n",
       "      <td>HR</td>\n",
       "      <td>52000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Name Department  Salary  Years_at_Company\n",
       "a    Alice         HR   50000                 2\n",
       "b      Bob         IT   60000                 5\n",
       "c  Charlie    Finance   55000                 3\n",
       "d    Diana         IT   65000                 7\n",
       "e    Ethan         HR   52000                 1"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Write a query to select the names of the people that earn more than 53000.\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27d0ac1d-0ebb-47a4-8928-41cb9cbf7660",
   "metadata": {},
   "source": [
    "# [`pd.loc`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.loc.html) and [`pd.iloc`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.iloc.html) functions\n",
    "\n",
    "Pandas offers additional ways to select rows and columns:\n",
    "\n",
    "- [`pd.loc`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.loc.html): allows you to select rows and columns by the index value.\n",
    "- [`pd.iloc`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.iloc.html): allows you to select rows and columns by the integer position. It is actually deprecated.\n",
    "\n",
    "You can access the second row by either using the index value `'b'` (and function `.loc`) or by integer position 1 (and function `.iloc`) as in the following example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4c1cebe6-1ab6-4bb4-bbe6-124c7d6473d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Name                  Bob\n",
       "Department             IT\n",
       "Salary              60000\n",
       "Years_at_Company        5\n",
       "Name: b, dtype: object"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc['b']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "82004b3d-83d8-4a7e-9eaf-14fff867fac0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Name                  Bob\n",
       "Department             IT\n",
       "Salary              60000\n",
       "Years_at_Company        5\n",
       "Name: b, dtype: object"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1570bbdb-522e-4514-9412-fa628677bee5",
   "metadata": {},
   "source": [
    "If you read more carefully the documentation of the two functions, you will see that, indeed, both [`pd.loc`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.loc.html) and [`pd.iloc`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.iloc.html) allow more flexibility like selecting intervals, arrays of booleans and so on."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a14671a2-9cb2-44b2-b6a8-9857118c858b",
   "metadata": {},
   "source": [
    "## Apply functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70d2b2c9-7572-4552-9696-db14eb6fb59f",
   "metadata": {},
   "source": [
    "Anothe common feature of pandas, is applying functions element-wise to columns: see below for an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1f7ad95e-bc8c-4f59-8f63-402e0721b910",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a    100000\n",
       "b    120000\n",
       "c    110000\n",
       "d    130000\n",
       "e    104000\n",
       "Name: Salary, dtype: int64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Double every salary:\n",
    "df['Salary'].apply(lambda x: x * 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b4154fb-9c0f-4999-bb6b-3223c5d69a57",
   "metadata": {},
   "source": [
    "What is [`lambda`](https://www.w3schools.com/python/python_lambda.asp) above?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17d26a8b-655b-4ddf-acbf-fca9c05783c7",
   "metadata": {},
   "source": [
    "As a final exercise, write a query for the names of the employees with a salary above 51000 and below 56000 using the `.apply` operator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b2735c01-3492-4a55-94c5-d8e6721ce1a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Department</th>\n",
       "      <th>Salary</th>\n",
       "      <th>Years_at_Company</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>a</th>\n",
       "      <td>Alice</td>\n",
       "      <td>HR</td>\n",
       "      <td>50000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b</th>\n",
       "      <td>Bob</td>\n",
       "      <td>IT</td>\n",
       "      <td>60000</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c</th>\n",
       "      <td>Charlie</td>\n",
       "      <td>Finance</td>\n",
       "      <td>55000</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d</th>\n",
       "      <td>Diana</td>\n",
       "      <td>IT</td>\n",
       "      <td>65000</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>e</th>\n",
       "      <td>Ethan</td>\n",
       "      <td>HR</td>\n",
       "      <td>52000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Name Department  Salary  Years_at_Company\n",
       "a    Alice         HR   50000                 2\n",
       "b      Bob         IT   60000                 5\n",
       "c  Charlie    Finance   55000                 3\n",
       "d    Diana         IT   65000                 7\n",
       "e    Ethan         HR   52000                 1"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Write a query to select the names of the people that earn a salary between 51000 and 56000. Use the .apply() operator.\n",
    "df\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dllab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
